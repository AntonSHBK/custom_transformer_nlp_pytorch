{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data:\n",
    "- [OPUS](https://opus.nlpl.eu/)\n",
    "- [WMT](https://www.statmt.org/wmt20/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = Path('imgs/')\n",
    "DATA_PATH = Path('data/')\n",
    "\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    random.seed(seed)\n",
    "\n",
    "seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "def download_and_unpack(url, output_path):\n",
    "    \"\"\" Скачивание файла и его распаковка. \"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(\"Download completed.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Failed to download file.\")\n",
    "        return False\n",
    "\n",
    "def extract_gz(file_path, extract_to):\n",
    "    \"\"\" Распаковка gz архива. \"\"\"\n",
    "    with gzip.open(file_path, 'rb') as f_in:\n",
    "        with open(extract_to, 'wb') as f_out:\n",
    "            f_out.write(f_in.read())\n",
    "    print(\"Extraction completed.\")\n",
    "\n",
    "def read_tmx_to_dataframe(tmx_path):\n",
    "    \"\"\" Чтение TMX файла и преобразование в DataFrame. \"\"\"\n",
    "    tree = ET.parse(tmx_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    data = []\n",
    "    for tu in root.findall('.//tu'):\n",
    "        tuv = tu.findall('tuv')\n",
    "        if len(tuv) >= 2:\n",
    "            src_text = tuv[0].find('seg').text\n",
    "            trg_text = tuv[1].find('seg').text\n",
    "            data.append({'source': src_text, 'target': trg_text})\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m download_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men-ru.tmx.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m tmx_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men-ru.tmx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdownload_and_unpack\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     11\u001b[0m     extract_gz(download_path, tmx_path)\n\u001b[0;32m     12\u001b[0m     dataframe \u001b[38;5;241m=\u001b[39m read_tmx_to_dataframe(tmx_path)\n",
      "Cell \u001b[1;32mIn[38], line 9\u001b[0m, in \u001b[0;36mdownload_and_unpack\u001b[1;34m(url, output_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_and_unpack\u001b[39m(url, output_path):\n\u001b[0;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Скачивание файла и его распаковка. \"\"\"\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Projects\\custom_transformer_nlp_pytorch\\.venv\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Projects\\custom_transformer_nlp_pytorch\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Projects\\custom_transformer_nlp_pytorch\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Projects\\custom_transformer_nlp_pytorch\\.venv\\Lib\\site-packages\\requests\\sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 747\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Projects\\custom_transformer_nlp_pytorch\\.venv\\Lib\\site-packages\\requests\\models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Projects\\custom_transformer_nlp_pytorch\\.venv\\Lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Projects\\custom_transformer_nlp_pytorch\\.venv\\Lib\\site-packages\\urllib3\\response.py:1043\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1043\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1045\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m   1046\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Projects\\custom_transformer_nlp_pytorch\\.venv\\Lib\\site-packages\\urllib3\\response.py:935\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[0;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[1;32m--> 935\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    937\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Projects\\custom_transformer_nlp_pytorch\\.venv\\Lib\\site-packages\\urllib3\\response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    859\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 862\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Projects\\custom_transformer_nlp_pytorch\\.venv\\Lib\\site-packages\\urllib3\\response.py:845\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\http\\client.py:472\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    471\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 472\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\ssl.py:1249\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1246\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1247\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1248\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "url = 'https://object.pouta.csc.fi/OPUS-wikimedia/v20230407/tmx/en-ru.tmx.gz'  # Замените на вашу ссылку\n",
    "# url = 'https://object.pouta.csc.fi/OPUS-Books/v1/tmx/en-ru.tmx.gz'  # Замените на вашу ссылку\n",
    "# url = 'https://object.pouta.csc.fi/OPUS-GNOME/v1/tmx/en-ru.tmx.gz'  # Замените на вашу ссылку\n",
    "\n",
    "# Укажите URL архива и локальные пути для сохранения\n",
    "download_path = os.path.join(DATA_PATH, 'en-ru.tmx.gz')\n",
    "tmx_path = os.path.join(DATA_PATH, 'en-ru.tmx')\n",
    "\n",
    "if download_and_unpack(url, download_path):\n",
    "    extract_gz(download_path, tmx_path)\n",
    "    dataframe = read_tmx_to_dataframe(tmx_path)\n",
    "    print(dataframe.head())\n",
    "\n",
    "    # Опционально: удаление временных файлов\n",
    "    # os.remove(download_path)\n",
    "    # os.remove(tmx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "\n",
    "# spacy.cli.download(\"en_core_web_sm\")\n",
    "# spacy.cli.download(\"ru_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmx_path = os.path.join(DATA_PATH, 'en-ru.tmx')\n",
    "dataframe = read_tmx_to_dataframe(tmx_path)\n",
    "dataframe = dataframe[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accerciser</td>\n",
       "      <td>Accerciser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Give your application an accessibility workout</td>\n",
       "      <td>Исследование поддержки вспомогательных технологий</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accerciser Accessibility Explorer</td>\n",
       "      <td>Изучение доступности приложений Accerciser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The default plugin layout for the bottom panel</td>\n",
       "      <td>Расположение модулей внизу рабочей области по ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The default plugin layout for the top panel</td>\n",
       "      <td>Расположение модулей вверху рабочей области по...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           source  \\\n",
       "0                                      Accerciser   \n",
       "1  Give your application an accessibility workout   \n",
       "2               Accerciser Accessibility Explorer   \n",
       "3  The default plugin layout for the bottom panel   \n",
       "4     The default plugin layout for the top panel   \n",
       "\n",
       "                                              target  \n",
       "0                                         Accerciser  \n",
       "1  Исследование поддержки вспомогательных технологий  \n",
       "2         Изучение доступности приложений Accerciser  \n",
       "3  Расположение модулей внизу рабочей области по ...  \n",
       "4  Расположение модулей вверху рабочей области по...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 149 entries, 0 to 148\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   source  149 non-null    object\n",
      " 1   target  149 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление пропусков в датафрейме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очистка данных от пустых строк и None\n",
    "dataframe = dataframe.dropna()  # Удаление строк, где есть хотя бы один None\n",
    "dataframe = dataframe[dataframe['source'].str.strip().astype(bool) & dataframe['target'].str.strip().astype(bool)]  # Удаление пустых строк\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упрощение последовательностей (удаление стоп слов, лемматизация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# import pandas as pd\n",
    "# from spacy.lang.en.stop_words import STOP_WORDS as en_stop\n",
    "# from spacy.lang.ru.stop_words import STOP_WORDS as ru_stop\n",
    "\n",
    "# nlp_en = spacy.load('en_core_web_sm')\n",
    "# nlp_ru = spacy.load('ru_core_news_sm')\n",
    "\n",
    "# def preprocess_text(text, nlp, stop_words):\n",
    "#     doc = nlp(text)\n",
    "#     result = []\n",
    "#     for token in doc:\n",
    "#         # Удаление стоп-слов и пунктуации, проверка на наличие алфавитных символов\n",
    "#         if token.text.lower() not in stop_words and token.is_alpha:\n",
    "#             result.append(token.lemma_)\n",
    "#     return \" \".join(result)\n",
    "\n",
    "# def preprocess_dataframe(df):\n",
    "#     # Применяем предобработку к каждому предложению в столбцах 'source' и 'target'\n",
    "#     df['source'] = df['source'].apply(lambda x: preprocess_text(x, nlp_en, en_stop))\n",
    "#     df['target'] = df['target'].apply(lambda x: preprocess_text(x, nlp_ru, ru_stop))\n",
    "#     return df\n",
    "\n",
    "# # Предобработка данных\n",
    "# dataframe = preprocess_dataframe(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет\n",
    "## Токенизация и создание словарей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\custom_transformer_nlp_pytorch\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class TextTokenizer:\n",
    "    def __init__(self, lang, max_vocab_size=10000, min_freq=1, max_length=100):\n",
    "        self.tokenizer = spacy.load(lang)\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.min_freq = min_freq\n",
    "        self.max_length = max_length\n",
    "        self.vocab = None\n",
    "        \n",
    "        self.specials = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        return ['<bos>'] +[token.text.lower() for token in self.tokenizer(text)] + ['<eos>']\n",
    "\n",
    "    def build_vocab(self, data):\n",
    "        token_stream = (self._tokenize(sentence) for sentence in tqdm(data, desc=\"Vocab build\"))\n",
    "        \n",
    "        self.vocab = build_vocab_from_iterator(token_stream, max_tokens=self.max_vocab_size, specials=self.specials, special_first=True)\n",
    "        self.vocab.set_default_index(self.vocab['<unk>'])\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        tokenized_text = self._tokenize(text)[:self.max_length]\n",
    "        return [self.vocab[token] for token in tokenized_text]\n",
    "\n",
    "    def detokenize(self, numericalized_text):\n",
    "        decoded_text = [self.vocab.get_itos()[index] \\\n",
    "            for index in numericalized_text \\\n",
    "                if self.vocab.get_itos()[index] not in self.specials]\n",
    "        return ' '.join(decoded_text)\n",
    "\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 dataframe: pd.DataFrame, \n",
    "                 src_col: str, \n",
    "                 trg_col: str, \n",
    "                 tokenizer_src: TextTokenizer, \n",
    "                 tokenizer_trg: TextTokenizer, \n",
    "                 padding_value=1):\n",
    "        self.dataframe = dataframe\n",
    "        self.src_col = src_col\n",
    "        self.trg_col = trg_col\n",
    "        self.tokenizer_src = tokenizer_src\n",
    "        self.tokenizer_trg = tokenizer_trg\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_sentence = self.dataframe.iloc[idx][self.src_col]\n",
    "        trg_sentence = self.dataframe.iloc[idx][self.trg_col]\n",
    "        tokenized_src = self.tokenizer_src.tokenize(src_sentence)\n",
    "        tokenized_trg = self.tokenizer_trg.tokenize(trg_sentence)\n",
    "        return {\n",
    "            \"src\": torch.tensor(tokenized_src, dtype=torch.long),\n",
    "            \"trg\": torch.tensor(tokenized_trg, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        src_batch = [item['src'] for item in batch]\n",
    "        trg_batch = [item['trg'] for item in batch]\n",
    "        src_padded = pad_sequence(src_batch, padding_value=self.padding_value, batch_first=True)\n",
    "        trg_padded = pad_sequence(trg_batch, padding_value=self.padding_value, batch_first=True)\n",
    "        return {\"src\": src_padded, \"trg\": trg_padded}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data = {'source': [\"Hello world\", \"How are you?\"], 'target': [\"Привет мир\", \"Как у тебя дела?\"]}\n",
    "# # df = pd.DataFrame(data)\n",
    "\n",
    "# # Создание токенизаторов и построение словарей\n",
    "# tokenizer_src = TextTokenizer(lang='en_core_web_sm')\n",
    "# tokenizer_trg = TextTokenizer(lang='ru_core_news_sm')\n",
    "# tokenizer_src.build_vocab(dataframe['source'])\n",
    "# tokenizer_trg.build_vocab(dataframe['target'])\n",
    "\n",
    "# # Разделение данных на обучающие и тестовые наборы\n",
    "# # train_df, val_df = train_test_split(dataframe, test_size=test_size, random_state=42)\n",
    "\n",
    "# # Пример использования\n",
    "# sample_text = \"Hello world\"\n",
    "# numericalized = tokenizer_src.tokenize(sample_text)\n",
    "# print(\"Numericalized:\", numericalized)\n",
    "# print(\"Detokenized:\", tokenizer_src.detokenize(numericalized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = TranslationDataset(dataframe, 'source', 'target', tokenizer_src, tokenizer_trg)\n",
    "\n",
    "# dataloader = DataLoader(dataset, batch_size=2, collate_fn=dataset.collate_fn)\n",
    "\n",
    "# for bath in tqdm(dataloader, desc=\"Testing dataloader\"):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Класс для реализации механизма Self-Attention.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_size, heads, dropout_rate=0.1, scale_factor=None):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        \n",
    "        self.embed_size = embed_size  # Размерность эмбеддинга\n",
    "        self.heads = heads  # Количество attention heads\n",
    "        self.head_dim = embed_size // heads  # Размерность для каждой головы внимания\n",
    "        self.scale_factor = scale_factor if scale_factor is not None \\\n",
    "            else (self.embed_size ** 0.5)\n",
    "\n",
    "        assert (\n",
    "            self.head_dim * heads == embed_size\n",
    "        ), \"Embedding size должен быть кратен количеству голов\"\n",
    "\n",
    "        # Инициализация весов для query, key и value\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        # Объединение результатов голов внимания\n",
    "        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, values, keys, queries, mask):\n",
    "        # Получение размера пакета\n",
    "        batch_size = queries.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], queries.shape[1]\n",
    "\n",
    "        # Разбиваем входные тензоры на головы\n",
    "        values = values.reshape(batch_size, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(batch_size, key_len, self.heads, self.head_dim)\n",
    "        queries = queries.reshape(batch_size, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        values = self.values(values)  # Применяем линейные преобразования к значениям\n",
    "        keys = self.keys(keys)  # Применяем линейные преобразования к ключам\n",
    "        queries = self.queries(queries)  # Применяем линейные преобразования к запросам\n",
    "\n",
    "        # Multiplying queries and keys for attention scores (N, heads, query_len, key_len)\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "        \n",
    "        # Apply mask to the attention scores\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        # Normalizing the attention scores using softmax\n",
    "        attention = torch.softmax(energy / self.scale_factor, dim=-1)\n",
    "        \n",
    "        # Apply dropout to attention\n",
    "        attention = self.dropout(attention)\n",
    "\n",
    "        # Multiplying the attention scores with the values\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            batch_size, query_len, self.heads * self.head_dim\n",
    "        )\n",
    "                \n",
    "        # Final linear layer\n",
    "        out = self.fc_out(out)\n",
    "        return out, attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Класс для одного блока Transformer, включающий в себя Self-Attention и Feed Forward сеть.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)  # Создаем слой Self-Attention\n",
    "        self.norm1 = nn.LayerNorm(embed_size)  # Слой нормализации для residual connection после attention\n",
    "        self.norm2 = nn.LayerNorm(embed_size)  # Слой нормализации для residual connection после feed forward\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion * embed_size),  # Линейный слой\n",
    "            nn.ReLU(),  # Функция активации ReLU\n",
    "            nn.Linear(forward_expansion * embed_size, embed_size),  # Линейный слой\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)  # Слой dropout для регуляризации\n",
    "\n",
    "    def forward(self, value, key, query, mask):\n",
    "        \"\"\"\n",
    "        Прохождение входных данных через блок Transformer.\n",
    "\n",
    "        Аргументы:\n",
    "            value: Тензор значений размером (batch_size, seq_length, embed_size)\n",
    "            key: Тензор ключей размером (batch_size, seq_length, embed_size)\n",
    "            query: Тензор запросов размером (batch_size, seq_length, embed_size)\n",
    "            mask: Маска внимания для исключения паддинга, размером (batch_size, 1, seq_length)\n",
    "\n",
    "        Возвращает:\n",
    "            out: Результат прохождения данных через блок Transformer\n",
    "        \"\"\"\n",
    "        # Проходим через механизм Self-Attention\n",
    "        attention_out, _ = self.attention(value, key, query, mask)\n",
    "        # Применяем residual connection и нормализацию\n",
    "        x = self.dropout(self.norm1(attention_out + query))\n",
    "        # Проходим через feed forward сеть\n",
    "        forward_out = self.feed_forward(x)\n",
    "        # Применяем residual connection и нормализацию\n",
    "        out = self.dropout(self.norm2(forward_out + x))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Класс для Encoder части Transformer, содержащий стек Transformer блоков.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 src_vocab_size, \n",
    "                 embed_size, \n",
    "                 num_layers, \n",
    "                 heads, \n",
    "                 device, \n",
    "                 forward_expansion, \n",
    "                 dropout, \n",
    "                 max_length):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(src_vocab_size, embed_size)  # Создаем эмбеддинги слов\n",
    "        self.position_embedding = nn.Embedding(max_length, embed_size)  # Создаем позиционные эмбеддинги\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    embed_size, \n",
    "                    heads, \n",
    "                    dropout, \n",
    "                    forward_expansion\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )  # Создаем стек блоков Transformer\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Прохождение входных данных через стек блоков Transformer Encoder.\n",
    "\n",
    "        Аргументы:\n",
    "            x: Тензор входных данных размером (batch_size, src_seq_length)\n",
    "            mask: Маска внимания для исключения паддинга, размером (batch_size, 1, src_seq_length)\n",
    "\n",
    "        Возвращает:\n",
    "            out: Результат прохождения данных через стек блоков Transformer Encoder\n",
    "        \"\"\"\n",
    "        batch_size, seq_length = x.shape\n",
    "        positions = torch.arange(0, seq_length).expand(batch_size, seq_length).to(self.device)  # Генерируем позиции\n",
    "        \n",
    "        # Получаем эмбеддинги слов и позиций и суммируем их\n",
    "        out = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n",
    "\n",
    "        # Проходим через стек блоков Transformer\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, mask)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecoderBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Класс для блока Decoder, который включает в себя Self-Attention, Encoder-Decoder Attention и Feed Forward.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout, device):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)  # Создаем слой Self-Attention\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        self.norm3 = nn.LayerNorm(embed_size)\n",
    "        self.encoder_decoder_attention = SelfAttention(embed_size, heads)  # Создаем слой внимания между Decoder и Encoder\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion * embed_size),  # Линейный слой\n",
    "            nn.ReLU(),  # Функция активации ReLU\n",
    "            nn.Linear(forward_expansion * embed_size, embed_size),  # Линейный слой\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)  # Слой dropout для регуляризации\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x, value, key, src_mask, trg_mask):\n",
    "        \"\"\"\n",
    "        Прохождение входных данных через блок Decoder.\n",
    "\n",
    "        Аргументы:\n",
    "            x: Тензор входных данных размером (batch_size, trg_seq_length, embed_size)\n",
    "            value: Тензор значений размером (batch_size, src_seq_length, embed_size)\n",
    "            key: Тензор ключей размером (batch_size, src_seq_length, embed_size)\n",
    "            src_mask: Маска внимания для исключения паддинга в Encoder, размером (batch_size, 1, src_seq_length)\n",
    "            trg_mask: Маска внимания для исключения предсказаний из будущего, размером (batch_size, trg_seq_length, trg_seq_length)\n",
    "\n",
    "        Возвращает:\n",
    "            out: Результат прохождения данных через блок Decoder\n",
    "        \"\"\"\n",
    "        # Проходим через механизм Self-Attention внутри Decoder\n",
    "        attention_out, _ = self.attention(x, x, x, trg_mask)\n",
    "        # Применяем residual connection и нормализацию\n",
    "        query = self.dropout(self.norm1(attention_out + x))\n",
    "        \n",
    "        # Проходим через механизм внимания между Decoder и Encoder\n",
    "        encoder_decoder_attention_out, _ = self.encoder_decoder_attention(value, key, query, src_mask)\n",
    "        # Применяем residual connection и нормализацию\n",
    "        query = self.dropout(self.norm2(encoder_decoder_attention_out + query))\n",
    "\n",
    "        # Проходим через feed forward сеть\n",
    "        forward_out = self.feed_forward(query)\n",
    "        # Применяем residual connection и нормализацию\n",
    "        out = self.dropout(self.norm3(forward_out + query))\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Класс для Decoder части Transformer.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        trg_vocab_size, \n",
    "        embed_size, \n",
    "        num_layers, \n",
    "        heads, \n",
    "        forward_expansion, \n",
    "        dropout, \n",
    "        device, \n",
    "        max_length):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)  # Создаем эмбеддинги слов\n",
    "        self.position_embedding = nn.Embedding(max_length, embed_size)  # Создаем позиционные эмбеддинги\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderBlock(embed_size, heads, forward_expansion, dropout, device)\n",
    "            for _ in range(num_layers)\n",
    "        ])  # Создаем стек блоков Decoder\n",
    "        \n",
    "        self.fc_out = nn.Linear(embed_size, trg_vocab_size)  # Финальный линейный слой для предсказания слов\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, src_mask, trg_mask):\n",
    "        \"\"\"\n",
    "        Прохождение входных данных через Decoder модель Transformer.\n",
    "\n",
    "        Аргументы:\n",
    "            x: Тензор входных данных размером (batch_size, trg_seq_length)\n",
    "            enc_out: Выходные данные Encoder размером (batch_size, src_seq_length, embed_size)\n",
    "            src_mask: Маска внимания для исключения паддинга в Encoder, размером (batch_size, 1, src_seq_length)\n",
    "            trg_mask: Маска внимания для исключения предсказаний из будущего, размером (batch_size, trg_seq_length, trg_seq_length)\n",
    "\n",
    "        Возвращает:\n",
    "            out: Результат прохождения данных через Decoder модель Transformer\n",
    "        \"\"\"\n",
    "        batch_size, trg_seq_length = x.shape\n",
    "        positions = torch.arange(0, trg_seq_length).expand(batch_size, trg_seq_length).to(self.device)  # Генерируем позиции\n",
    "\n",
    "        # Получаем эмбеддинги слов и позиций и суммируем их\n",
    "        x = self.dropout((self.word_embedding(x) + self.position_embedding(positions)))\n",
    "\n",
    "        # Проходим через стек блоков Decoder\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n",
    "\n",
    "        out = self.fc_out(x)  # Применяем линейный слой для предсказания следующего слова\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Класс, интегрирующий Encoder и Decoder в полную модель Transformer.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 src_vocab_size, \n",
    "                 trg_vocab_size, \n",
    "                 src_pad_idx, \n",
    "                 trg_pad_idx, \n",
    "                 embed_size=256, \n",
    "                 num_layers=6, \n",
    "                 forward_expansion=4, \n",
    "                 heads=8, \n",
    "                 dropout=0, \n",
    "                 device=\"cuda\", \n",
    "                 max_length=100):\n",
    "        \n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(\n",
    "            src_vocab_size,\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            device,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_length\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            trg_vocab_size,\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            device,\n",
    "            max_length\n",
    "        )\n",
    "        \n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        \"\"\"\n",
    "        Создание маски для исключения влияния padding токенов в процессе внимания.\n",
    "\n",
    "        Аргументы:\n",
    "            src: Тензор исходных данных размером (batch_size, src_seq_length)\n",
    "\n",
    "        Возвращает:\n",
    "            src_mask: Маска для исключения padding токенов размером (batch_size, 1, 1, src_seq_length)\n",
    "        \"\"\"\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        # (batch_size, 1, 1, src_len) для работы с механизмом внимания\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        batch_size, trg_len = trg.size()\n",
    "        no_peak_mask = torch.tril(torch.ones((1, trg_len, trg_len), device=self.device)).bool()\n",
    "        pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        trg_mask = no_peak_mask & pad_mask\n",
    "        return trg_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        \"\"\"\n",
    "        Полный проход через модель.\n",
    "\n",
    "        Аргументы:\n",
    "            src: Тензор исходных данных размером (batch_size, src_seq_length)\n",
    "            trg: Тензор целевых данных размером (batch_size, trg_seq_length)\n",
    "\n",
    "        Возвращает:\n",
    "            output: Результат предсказания модели размером (batch_size, trg_seq_length, trg_vocab_size)\n",
    "        \"\"\"\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        enc_out = self.encoder(src, src_mask)\n",
    "        output = self.decoder(trg, enc_out, src_mask, trg_mask)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    src_vocab_size = 32000  # Предполагаем, что у нас есть 32K уникальных токенов для исходного языка\n",
    "    trg_vocab_size = 32000  # и для целевого языка\n",
    "    embed_size = 512        # Размер эмбеддингов\n",
    "    num_layers = 6          # Количество слоев в энкодере и декодере\n",
    "    forward_expansion = 4   # Коэффициент увеличения для полносвязного слоя\n",
    "    heads = 8               # Количество голов в механизме многослойного внимания\n",
    "    dropout = 0.1           # Вероятность dropout\n",
    "    max_length = 100        # Максимальная длина последовательности\n",
    "    min_freq = 2\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')         # Устройство для тренировки: 'cuda' или 'cpu'\n",
    "    learning_rate = 0.0005  # Скорость обучения\n",
    "    batch_size = 64         # Размер батча для обучения\n",
    "    clip = 1\n",
    "    num_epochs = 10\n",
    "    test_size = 0.1\n",
    "    printing_period = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, \n",
    "                 tokenizer_src: TextTokenizer, \n",
    "                 tokenizer_trg: TextTokenizer,\n",
    "                 weights={'bleu': 0.34, 'rouge': 0.33, 'meteor': 0.33}):\n",
    "        \"\"\"\n",
    "        Инициализация Evaluator с токенизаторами для исходного и целевого языков.\n",
    "\n",
    "        :param tokenizer_src: Токенизатор для исходного языка.\n",
    "        :param tokenizer_trg: Токенизатор для целевого языка.\n",
    "        :param weights: Веса.\n",
    "        \"\"\"\n",
    "        self.tokenizer_src = tokenizer_src\n",
    "        self.tokenizer_trg = tokenizer_trg\n",
    "        self.weights = weights        \n",
    "        self.rouge = Rouge()\n",
    "\n",
    "    def evaluate(self, model, dataloader):\n",
    "        \"\"\"\n",
    "        Оценивает модель на данных, загруженных через data_loader.\n",
    "\n",
    "        :param model: Модель для оценки.\n",
    "        :param data_loader: DataLoader, предоставляющий данные для оценки.\n",
    "        :return: Словарь с результатами по метрикам.\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        references = []\n",
    "        hypotheses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                src  = batch['src']\n",
    "                trg  = batch['trg']\n",
    "\n",
    "                # Генерация вывода модели\n",
    "                output = model(src, trg[:, :-1])  # Исключаем токен <eos>\n",
    "                output = output.argmax(-1)\n",
    "                \n",
    "                # Детокенизация результата\n",
    "                for true, pred in zip(trg, output):\n",
    "                    true_sentence = self.tokenizer_trg.detokenize(true.numpy())\n",
    "                    pred_sentence = self.tokenizer_trg.detokenize(pred.numpy())\n",
    "                    references.append([true_sentence])\n",
    "                    hypotheses.append(pred_sentence)\n",
    "\n",
    "        # Вычисление метрик BLEU, ROUGE, METEOR\n",
    "        bleu_score = corpus_bleu(references, hypotheses)\n",
    "        # rouge_scores = self.rouge.get_scores(hypotheses, [' '.join(ref[0]) for ref in references], avg=True)\n",
    "        # rouge_score = rouge_scores['rouge-l']['f']\n",
    "        rouge_score = 0\n",
    "        # list_meteor_score = [meteor_score([ref[0]], hyp) for ref, hyp in zip(references, hypotheses)]\n",
    "        # avg_meteor_score = np.mean(list_meteor_score)\n",
    "        avg_meteor_score = 0\n",
    "\n",
    "        # Словарь с результатами\n",
    "        results = {\n",
    "            'overall': self.weights['bleu'] * bleu_score +\n",
    "                       self.weights['rouge'] * rouge_score +\n",
    "                       self.weights['meteor'] * avg_meteor_score,\n",
    "            'bleu': bleu_score,\n",
    "            'rouge': rouge_score,\n",
    "            'meteor': avg_meteor_score\n",
    "        }\n",
    "        return results\n",
    "    \n",
    "    def evaluate_on_indices(self, model, dataloader):\n",
    "        \"\"\"\n",
    "        Оценивает модель на данных, используя индексы токенов для вычисления BLEU.\n",
    "\n",
    "        :param model: Модель для оценки.\n",
    "        :param data_loader: DataLoader, предоставляющий данные для оценки.\n",
    "        :return: Словарь с результатами метрики BLEU.\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        references = []\n",
    "        hypotheses = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                src  = batch['src']\n",
    "                trg  = batch['trg']\n",
    "                \n",
    "                # Генерация вывода модели\n",
    "                output = model(src, trg[:, :-1])\n",
    "                output = output.argmax(-1)\n",
    "                \n",
    "                # Сохранение индексов без детокенизации\n",
    "                for true, pred in zip(trg, output):\n",
    "                    # Убираем индексы для специальных токенов\n",
    "                    true_indices = [token for token in true.numpy() \\\n",
    "                        if token not in [self.tokenizer_trg.vocab[spec] \\\n",
    "                            for spec in self.tokenizer_trg.specials]]\n",
    "                    pred_indices = [token for token in pred.numpy() \\\n",
    "                        if token not in [self.tokenizer_trg.vocab[spec] \\\n",
    "                            for spec in self.tokenizer_trg.specials]]\n",
    "                    \n",
    "                    references.append([true_indices])\n",
    "                    hypotheses.append(pred_indices)\n",
    "\n",
    "        # Вычисление метрик BLEU, ROUGE, METEOR\n",
    "        bleu_score = corpus_bleu(references, hypotheses)\n",
    "        rouge_score = self.rouge.get_scores(hypotheses, references, avg=True)['f']\n",
    "        # list_meteor_score = [meteor_score([ref], hyp) for ref, hyp in zip(references, hypotheses)]\n",
    "        # avg_meteor_score = np.mean(list_meteor_score)\n",
    "        avg_meteor_score = 0\n",
    "\n",
    "        # Словарь с результатами\n",
    "        results = {\n",
    "            'overall': self.weights['bleu'] * bleu_score +\n",
    "                       self.weights['rouge'] * rouge_score +\n",
    "                       self.weights['meteor'] * avg_meteor_score,\n",
    "            'bleu': bleu_score,\n",
    "            'rouge': rouge_score,\n",
    "            'meteor': avg_meteor_score\n",
    "        }\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, \n",
    "                 model:Transformer, \n",
    "                 evaluator: Evaluator, \n",
    "                 optimizer:nn.CrossEntropyLoss,\n",
    "                 criterion:optim.Adam,\n",
    "                 clip=1,\n",
    "                 device='cuda',\n",
    "                 printing_period=None,\n",
    "                 imgs_path=Path(''),\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Инициализация Trainer для модели Transformer.\n",
    "        \"\"\"\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.evaluator = evaluator\n",
    "        self.clip = clip\n",
    "        \n",
    "        self.printing_period = printing_period\n",
    "        self.imgs_path = imgs_path\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.metrics = []\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def train(self, train_dataloader):\n",
    "        \"\"\"\n",
    "        Обучение модели\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "            src: Tensor = batch['src'].to(self.device)\n",
    "            trg: Tensor = batch['trg'].to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            output: Tensor = self.model(src, trg[:, :-1])\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            loss = self.criterion(output, trg)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Аккумулируем потери\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Вычисляем среднюю потерю за эпоху\n",
    "        avg_loss = train_loss / len(train_dataloader)\n",
    "        self.train_losses.append(avg_loss)\n",
    "        return avg_loss\n",
    "\n",
    "    def eval(self, val_dataloader):\n",
    "        \"\"\"\n",
    "        Валидация модели для оценки производительности на валидационном наборе данных.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        validation_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_dataloader, desc=\"Validating\"):\n",
    "                src: Tensor= batch['src'].to(self.device)\n",
    "                trg: Tensor = batch['trg'].to(self.device)     \n",
    "                           \n",
    "                output: Tensor = self.model(src, trg[:, :-1])\n",
    "                output_dim = output.shape[-1]\n",
    "\n",
    "                output = output.contiguous().view(-1, output_dim)\n",
    "                trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "                loss = self.criterion(output, trg)\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "        avg_loss = validation_loss / len(val_dataloader)\n",
    "        self.val_losses.append(avg_loss)\n",
    "        \n",
    "        return avg_loss\n",
    "    \n",
    "    def special_metrics(self, val_dataloader):\n",
    "        metric_scores = self.evaluator.evaluate(self.model, val_dataloader)\n",
    "        self.metrics.append(metric_scores)\n",
    "        return metric_scores\n",
    "        \n",
    "    def fit(self, num_epochs, train_dataloader, val_dataloader):\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_loss = self.train(train_dataloader)\n",
    "            val_epoch_loss = self.eval(val_dataloader)   \n",
    "                 \n",
    "            if self.printing_period and (epoch + 1) % self.printing_period == 0:\n",
    "                self.special_metrics(val_dataloader)\n",
    "                print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Val Loss: {val_epoch_loss:.4f}')\n",
    "                \n",
    "        return val_epoch_loss\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"\n",
    "        Сохранение обученной модели.\n",
    "\n",
    "        Параметры:\n",
    "            path: путь для сохранения модели.\n",
    "        \"\"\"\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        \"\"\"\n",
    "        Загрузка модели из файла.\n",
    "\n",
    "        Параметры:\n",
    "            path: путь к файлу с сохраненной моделью.\n",
    "        \"\"\"\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "    def _save_fig(self, fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "        path = self.imgs_path / f\"{fig_id}.{fig_extension}\"\n",
    "        if tight_layout:\n",
    "            plt.tight_layout()\n",
    "        plt.savefig(path, format=fig_extension, dpi=resolution) \n",
    "\n",
    "    def plot_metrics(self):\n",
    "        epochs_range = range(1, len(self.val_losses) + 1)\n",
    "        fig = plt.figure(figsize=(15, 6))  # Устанавливаем размер фигуры\n",
    "        \n",
    "        ax11 = plt.subplot()\n",
    "        ax11.plot(epochs_range, self.train_losses, label='Train Loss', color='tab:red')\n",
    "        ax11.plot(epochs_range, self.val_losses, label='Validation Loss', color='tab:blue')\n",
    "        ax11.set_title('Losses over Epochs')\n",
    "        ax11.set_xlabel('Epochs')\n",
    "        ax11.set_ylabel('Loss')\n",
    "        # ax11.tick_params(axis='y', labelcolor='tab:red')\n",
    "        ax11.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        ax11.legend(loc='upper right')     \n",
    "\n",
    "        fig.tight_layout()  # Убедимся, что макет не нарушен\n",
    "        self._save_fig(\"train_metrics\")  # extra code\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_special_metrics(self):\n",
    "        epochs_range = range(1, len(self.metrics) + 1)\n",
    "        fig = plt.figure(figsize=(15, 6))  # Устанавливаем размер фигуры\n",
    "        \n",
    "        ax12 = plt.subplot(1, 2, 1)\n",
    "        ax12.plot(epochs_range, [m['overall'] for m in self.metrics], label='Overall Score', color='tab:green')\n",
    "        ax12.set_title('Overall Evaluation Score')\n",
    "        ax12.set_xlabel('Epochs')\n",
    "        ax12.set_ylabel('Score')\n",
    "        ax12.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        ax12.legend(loc='upper right')\n",
    "\n",
    "        # Отдельные графики для каждой метрики\n",
    "        ax21 = plt.subplot(1, 2, 2)\n",
    "        ax21.plot(epochs_range, [m['bleu'] for m in self.metrics], label='BLEU Score', color='tab:red')\n",
    "        ax21.plot(epochs_range, [m['rouge'] for m in self.metrics], label='ROUGE Score', color='tab:pink')\n",
    "        ax21.plot(epochs_range, [m['meteor'] for m in self.metrics], label='METEOR Score', color='tab:brown')\n",
    "        ax21.set_title('Individual Metrics')\n",
    "        ax21.set_xlabel('Epochs')\n",
    "        ax21.set_ylabel('Score')\n",
    "        ax21.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        ax21.legend(loc='upper right')      \n",
    "\n",
    "        fig.tight_layout()  # Убедимся, что макет не нарушен\n",
    "        self._save_fig(\"special_metrics\")  # extra code\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "class TrainingManager:\n",
    "    def __init__(self, \n",
    "                 dataframe: pd.DataFrame,\n",
    "                 features: str, \n",
    "                 targets: str,\n",
    "                 config: Config,\n",
    "                 data_path=DATA_PATH,\n",
    "                 imgs_path=IMAGES_PATH):\n",
    "        \"\"\"\n",
    "        Инициализация менеджера обучения.        \n",
    "        :param features: Признаки для обучения модели.\n",
    "        :param targets: Целевые значения.\n",
    "        :param model_params: Параметры модели, включая размеры слоёв и функцию активации.\n",
    "        :param train_params: Параметры обучения, включая размер батча, количество эпох и скорость обучения.\n",
    "        \"\"\"\n",
    "        self.uniq_name = '_'.join(features + targets)\n",
    "        self.data_path = data_path  \n",
    "        self.imgs_path = imgs_path    \n",
    "        \n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.dataframe = dataframe\n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "        self.tokenizer_src = TextTokenizer(\n",
    "            lang='en_core_web_sm',\n",
    "            max_vocab_size=config.src_vocab_size,\n",
    "            min_freq=config.min_freq,\n",
    "            max_length=config.max_length    \n",
    "        )\n",
    "        self.tokenizer_trg = TextTokenizer(\n",
    "            lang='ru_core_news_sm',\n",
    "            max_vocab_size=config.trg_vocab_size,\n",
    "            min_freq=config.min_freq,\n",
    "            max_length=config.max_length\n",
    "        )\n",
    "        self.tokenizer_src.build_vocab(dataframe['source'])\n",
    "        self.tokenizer_trg.build_vocab(dataframe['target'])\n",
    "\n",
    "        train_df, val_df = train_test_split(dataframe, test_size=config.test_size, random_state=42)\n",
    "\n",
    "        train_dataset = TranslationDataset(\n",
    "            dataframe=train_df,\n",
    "            src_col='source',\n",
    "            trg_col='target',\n",
    "            tokenizer_src=self.tokenizer_src,\n",
    "            tokenizer_trg=self.tokenizer_trg,\n",
    "            padding_value=self.tokenizer_src.vocab['<pad>'],\n",
    "        )\n",
    "\n",
    "        val_dataset = TranslationDataset(\n",
    "            dataframe=val_df,\n",
    "            src_col='source',\n",
    "            trg_col='target',\n",
    "            tokenizer_src=self.tokenizer_src,\n",
    "            tokenizer_trg=self.tokenizer_trg,\n",
    "            padding_value=self.tokenizer_src.vocab['<pad>'],\n",
    "        )\n",
    "\n",
    "        self.train_dataloader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=config.batch_size, \n",
    "            collate_fn=train_dataset.collate_fn, \n",
    "            shuffle=True\n",
    "        )\n",
    "        self.val_dataloader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=config.batch_size, \n",
    "            collate_fn=val_dataset.collate_fn, \n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        # Шаг 1: Определение модели\n",
    "        model = Transformer(\n",
    "            src_vocab_size=len(self.tokenizer_src.vocab),\n",
    "            trg_vocab_size=len(self.tokenizer_trg.vocab),\n",
    "            src_pad_idx=self.tokenizer_src.vocab['<pad>'],\n",
    "            trg_pad_idx=self.tokenizer_trg.vocab['<pad>'],\n",
    "            embed_size=config.embed_size,\n",
    "            num_layers=config.num_layers,\n",
    "            forward_expansion=config.forward_expansion,\n",
    "            heads=config.heads,\n",
    "            dropout=config.dropout,\n",
    "            device=config.device\n",
    "        )\n",
    "\n",
    "        # Шаг 2: Определение функции потерь\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=self.tokenizer_src.vocab['<pad>'])\n",
    "\n",
    "        # Шаг 3: Определение оптимизатора\n",
    "        optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "        \n",
    "        evaluator = Evaluator(\n",
    "            self.tokenizer_src,\n",
    "            self.tokenizer_trg   \n",
    "        )\n",
    "        \n",
    "        self.trainer = Trainer(\n",
    "            model,\n",
    "            evaluator,\n",
    "            optimizer,\n",
    "            criterion,\n",
    "            clip=config.clip,\n",
    "            device=config.device,\n",
    "            printing_period=config.printing_period,\n",
    "            imgs_path=self.imgs_path    \n",
    "        )  \n",
    "    \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Запуск процесса обучения.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.trainer.fit(self.config.num_epochs, self.train_dataloader, self.val_dataloader)\n",
    "        self.trainer.plot_metrics()\n",
    "        self.trainer.plot_special_metrics()\n",
    "\n",
    "    # def predict(self, input, transform=True):\n",
    "    #     \"\"\"\n",
    "    #     Выполнение предсказаний с помощью обученной модели.\n",
    "    #     \"\"\"\n",
    "    #     features = input\n",
    "    #     if transform:\n",
    "    #         features = self.scaler_features.transform(input)\n",
    "    #     else:\n",
    "    #         features = input\n",
    "    #     scaled_predictions = self.trainer.predict(features)\n",
    "    #     return self.scaler_targets.inverse_transform(scaled_predictions)\n",
    "\n",
    "    # def save(self):\n",
    "    #     self._save_model()\n",
    "    #     self._save_standard_scalar()\n",
    " \n",
    "    # def load(self):\n",
    "    #     self._load_model()\n",
    "    #     self._load_standard_scalar()\n",
    "    \n",
    "    # def _save_model(self):\n",
    "    #     \"\"\"\n",
    "    #     Сохранение обученной модели.        \n",
    "    #     \"\"\"\n",
    "    #     self.trainer.save_model(self.data_path+self.uniq_name+'_model_weight.pth')\n",
    "        \n",
    "    # def _load_model(self):\n",
    "    #     \"\"\"\n",
    "    #     Загрузка обученной модели.        \n",
    "    #     \"\"\"\n",
    "    #     self.trainer = Trainer.load_model(self.data_path+self.uniq_name+'_model_weight.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config\n",
    "\n",
    "config.src_vocab_size = 10000  # Предполагаем, что у нас есть 32K уникальных токенов для исходного языка\n",
    "config.trg_vocab_size = 10000  # и для целевого языка\n",
    "config.embed_size = 64         # Размер эмбеддингов\n",
    "config.num_layers = 6          # Количество слоев в энкодере и декодере\n",
    "config.forward_expansion = 4   # Коэффициент увеличения для полносвязного слоя\n",
    "config.heads = 8               # Количество голов в механизме многослойного внимания\n",
    "config.dropout = 0.05           # Вероятность dropout\n",
    "config.min_freq = 2\n",
    "config.max_length = 100        # Максимальная длина последовательности\n",
    "config.device = \"cpu\"          # Устройство для тренировки: 'cuda' или 'cpu'\n",
    "config.learning_rate = 0.001  # Скорость обучения\n",
    "config.batch_size = 128          # Размер батча для обучения\n",
    "config.clip = 1                # \n",
    "config.num_epochs = 20\n",
    "config.test_size = 0.1\n",
    "config.printing_period =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.optim import Adam\n",
    "# from tqdm.auto import tqdm\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # Определение гиперпараметров\n",
    "# max_vocab_size = 10000\n",
    "# min_freq = 2\n",
    "# max_length = 80\n",
    "# embed_size = 64\n",
    "# num_layers = 3\n",
    "# forward_expansion = 2\n",
    "# heads = 4\n",
    "# dropout = 0.1\n",
    "# learning_rate = 0.001\n",
    "# batch_size = 256\n",
    "# num_epochs = 10\n",
    "# clip = 1\n",
    "# test_size = 0.1\n",
    "# device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Создание токенизаторов и построение словарей\n",
    "# tokenizer_src = TextTokenizer(\n",
    "#     lang='en_core_web_sm',\n",
    "#     max_vocab_size=max_vocab_size,\n",
    "#     min_freq=min_freq,\n",
    "#     max_length=max_length    \n",
    "# )\n",
    "# tokenizer_trg = TextTokenizer(\n",
    "#     lang='ru_core_news_sm',\n",
    "#     max_vocab_size=max_vocab_size,\n",
    "#     min_freq=min_freq,\n",
    "#     max_length=max_length\n",
    "# )\n",
    "# tokenizer_src.build_vocab(dataframe['source'])\n",
    "# tokenizer_trg.build_vocab(dataframe['target'])\n",
    "\n",
    "# train_df, val_df = train_test_split(dataframe, test_size=test_size, random_state=42)\n",
    "\n",
    "# train_dataset = TranslationDataset(\n",
    "#     dataframe=train_df,\n",
    "#     src_col='source',\n",
    "#     trg_col='target',\n",
    "#     tokenizer_src=tokenizer_src,\n",
    "#     tokenizer_trg=tokenizer_trg,\n",
    "#     padding_value=tokenizer_src.vocab['<pad>'],\n",
    "# )\n",
    "\n",
    "# val_dataset = TranslationDataset(\n",
    "#     dataframe=val_df,\n",
    "#     src_col='source',\n",
    "#     trg_col='target',\n",
    "#     tokenizer_src=tokenizer_src,\n",
    "#     tokenizer_trg=tokenizer_trg,\n",
    "#     padding_value=tokenizer_src.vocab['<pad>'],\n",
    "# )\n",
    "\n",
    "# train_dataloader = DataLoader(\n",
    "#     train_dataset, \n",
    "#     batch_size=batch_size, \n",
    "#     collate_fn=train_dataset.collate_fn, \n",
    "#     shuffle=True\n",
    "# )\n",
    "# val_dataloader = DataLoader(\n",
    "#     val_dataset, \n",
    "#     batch_size=batch_size, \n",
    "#     collate_fn=val_dataset.collate_fn, \n",
    "#     shuffle=False\n",
    "# )\n",
    "\n",
    "# # Шаг 1: Определение модели\n",
    "# model = Transformer(\n",
    "#     src_vocab_size=len(tokenizer_src.vocab),\n",
    "#     trg_vocab_size=len(tokenizer_trg.vocab),\n",
    "#     src_pad_idx=tokenizer_src.vocab['<pad>'],\n",
    "#     trg_pad_idx=tokenizer_trg.vocab['<pad>'],\n",
    "#     embed_size=embed_size,\n",
    "#     num_layers=num_layers,\n",
    "#     forward_expansion=forward_expansion,\n",
    "#     heads=heads,\n",
    "#     dropout=dropout,\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# # Шаг 2: Определение функции потерь\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index=tokenizer_src.vocab['<pad>'])\n",
    "\n",
    "# # Шаг 3: Определение оптимизатора\n",
    "# optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# evaluator = Evaluator(\n",
    "#     tokenizer_src,\n",
    "#     tokenizer_trg,    \n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Шаг 4: Обучение модели\n",
    "# def train(model: Transformer, iterator, optimizer: Adam, criterion: nn.CrossEntropyLoss, clip):\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "\n",
    "#     for batch in tqdm(iterator, desc=\"Training\"):\n",
    "#         src = batch[\"src\"]\n",
    "#         trg = batch[\"trg\"]\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(src, trg[:, :-1])\n",
    "#         output_dim = output.shape[-1]\n",
    "\n",
    "#         output = output.contiguous().view(-1, output_dim)\n",
    "#         trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "#         loss = criterion(output, trg)\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "#         optimizer.step()\n",
    "\n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#     return epoch_loss / len(iterator)\n",
    "\n",
    "# def evaluate(model, iterator, criterion):\n",
    "#     model.eval()\n",
    "#     epoch_loss = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(iterator, desc=\"Evaluation\"):\n",
    "#             src = batch[\"src\"]\n",
    "#             trg = batch[\"trg\"]\n",
    "\n",
    "#             output = model(src, trg[:, :-1])\n",
    "#             output_dim = output.shape[-1]\n",
    "\n",
    "#             output = output.contiguous().view(-1, output_dim)\n",
    "#             trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "#             loss = criterion(output, trg)\n",
    "#             epoch_loss += loss.item()\n",
    "\n",
    "#     return epoch_loss / len(iterator)\n",
    "\n",
    "# CLIP = 1\n",
    "\n",
    "# best_valid_loss = float('inf')\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "#     valid_loss = evaluate(model, val_dataloader, criterion)\n",
    "\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'transformer_model.pt')\n",
    "\n",
    "#     print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model,\n",
    "#     evaluator,\n",
    "#     optimizer,\n",
    "#     criterion,\n",
    "#     clip=clip,\n",
    "#     device=device,\n",
    "#     printing_period=1,\n",
    "#     imgs_path=IMAGES_PATH    \n",
    "# )\n",
    "# trainer.fit(\n",
    "#     num_epochs=num_epochs,\n",
    "#     train_dataloader=train_dataloader,\n",
    "#     val_dataloader=val_dataloader,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vocab build: 100%|██████████| 149/149 [00:00<00:00, 179.44it/s]\n",
      "Vocab build: 100%|██████████| 149/149 [00:00<00:00, 154.89it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer_manager = TrainingManager(\n",
    "    dataframe,\n",
    "    'source',\n",
    "    'target',\n",
    "    config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2/2 [00:02<00:00,  1.02s/it]\n",
      "Validating: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fraction.__new__() got an unexpected keyword argument '_normalize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 120\u001b[0m, in \u001b[0;36mTrainingManager.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    Запуск процесса обучения.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mplot_metrics()\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mplot_special_metrics()\n",
      "Cell \u001b[1;32mIn[25], line 103\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, num_epochs, train_dataloader, val_dataloader)\u001b[0m\n\u001b[0;32m    100\u001b[0m     val_epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(val_dataloader)   \n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprinting_period \u001b[38;5;129;01mand\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprinting_period \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 103\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspecial_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_epoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val_epoch_loss\n",
      "Cell \u001b[1;32mIn[25], line 93\u001b[0m, in \u001b[0;36mTrainer.special_metrics\u001b[1;34m(self, val_dataloader)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspecial_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m, val_dataloader):\n\u001b[1;32m---> 93\u001b[0m     metric_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mappend(metric_scores)\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metric_scores\n",
      "Cell \u001b[1;32mIn[24], line 52\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[1;34m(self, model, dataloader)\u001b[0m\n\u001b[0;32m     49\u001b[0m             hypotheses\u001b[38;5;241m.\u001b[39mappend(pred_sentence)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Вычисление метрик BLEU, ROUGE, METEOR\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m bleu_score \u001b[38;5;241m=\u001b[39m \u001b[43mcorpus_bleu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypotheses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# rouge_scores = self.rouge.get_scores(hypotheses, [' '.join(ref[0]) for ref in references], avg=True)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# rouge_score = rouge_scores['rouge-l']['f']\u001b[39;00m\n\u001b[0;32m     55\u001b[0m rouge_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Projects\\custom_transformer_nlp_pytorch\\.venv\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:210\u001b[0m, in \u001b[0;36mcorpus_bleu\u001b[1;34m(list_of_references, hypotheses, weights, smoothing_function, auto_reweigh)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m references, hypothesis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(list_of_references, hypotheses):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# For each order of ngram, calculate the numerator and\u001b[39;00m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# denominator for the corpus-level modified precision.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_weight_length \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 210\u001b[0m         p_i \u001b[38;5;241m=\u001b[39m \u001b[43mmodified_precision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m         p_numerators[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p_i\u001b[38;5;241m.\u001b[39mnumerator\n\u001b[0;32m    212\u001b[0m         p_denominators[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p_i\u001b[38;5;241m.\u001b[39mdenominator\n",
      "File \u001b[1;32mc:\\Projects\\custom_transformer_nlp_pytorch\\.venv\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:368\u001b[0m, in \u001b[0;36mmodified_precision\u001b[1;34m(references, hypothesis, n)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;66;03m# Ensures that denominator is minimum 1 to avoid ZeroDivisionError.\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;66;03m# Usually this happens when the ngram order is > len(reference).\u001b[39;00m\n\u001b[0;32m    366\u001b[0m denominator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28msum\u001b[39m(counts\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m--> 368\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenominator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_normalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Fraction.__new__() got an unexpected keyword argument '_normalize'"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer_manager.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предикт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выполнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
